{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23df5a5c-3a5f-4055-aa55-4bc88ec61d3f",
   "metadata": {},
   "source": [
    "# Project: Facial emotion recognition\n",
    "## MTH767P - Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b325e04-50c6-4e8a-9b86-100ae7feeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084313b-4ea4-4c58-af1d-2ddebfa3effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd624c-571b-40fe-a5e2-c6c02018dc46",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fa922",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionary for emotions\n",
    "emotion_dict = {0: 'Angry', \n",
    "                1: 'Disgust', \n",
    "                2: 'Fear',\n",
    "                3: 'Happy', \n",
    "                4: 'Sad',\n",
    "                5: 'Surprise',\n",
    "                6: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e918aa-e07f-4672-94dc-153de5c1d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "batch_size = 4\n",
    "dataset = EmotionsDataset(root='./data', fname='icml_face_data.csv', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1712e",
   "metadata": {},
   "source": [
    "#### Visualize data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b799acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample of images\n",
    "fig, ax = plt.subplots(batch_size, len(emotion_dict), figsize=(8, 4.5))\n",
    "\n",
    "for i, em in emotion_dict.items():\n",
    "    emotion = dataset.data[dataset.targets==i][:batch_size]\n",
    "    # set title\n",
    "    ax[0, i].set_title(em)\n",
    "    for j in range(emotion.shape[0]):      \n",
    "        im = emotion[j]\n",
    "        ax[j, i].imshow(im, cmap='gray')\n",
    "        ax[j, i].axis('off')\n",
    "plt.tight_layout();\n",
    "plt.savefig(output_path/'dataset_sample.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e4a53",
   "metadata": {},
   "source": [
    "#### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = dataset.split(ratio=0.8, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63719c2e-abb6-4685-b4c2-8e9acaab05dc",
   "metadata": {},
   "source": [
    "---\n",
    "## Convolutional neural network setup \n",
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ed94a-f412-4401-a020-972e008564bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of a simple convnet\n",
    "# Specify your model by providing the list of dicts, each containing the name of the layer class (case-insensitive) \n",
    "# and the parameters necessary to initialise it. The in_channels and in_features are not necessary as they are \n",
    "# calculated automatically\n",
    "# If the layer contains the activation function, give an initialised object of the relevant class\n",
    "\n",
    "layers = [dict(ltype='conv2d', out_channels=6, kernel=7, activation=nn.ReLU(True)),\n",
    "          dict(ltype='maxpool2d', kernel=2, stride=2),\n",
    "          dict(ltype='conv2d', out_channels=16, kernel=5),\n",
    "          dict(ltype='maxpool2d', kernel=2, stride=2, activation=nn.ReLU(True)),\n",
    "          dict(ltype='linear', out_features=120, activation=nn.ReLU(True)),\n",
    "          dict(ltype='linear', out_features=7)\n",
    "         ]\n",
    "net = ConvNet(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d4d78-f0af-4ba3-bafd-319e903c0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture with localization network (see Minaee 2021, and code in https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html)\n",
    "\n",
    "atn_layers = dict(\n",
    "            attention=[dict(ltype='conv2d', out_channels=8, kernel=3),\n",
    "                       dict(ltype='maxpool2d', kernel=2, stride=2, activation=nn.ReLU(True)),\n",
    "                       dict(ltype='conv2d', out_channels=10, kernel=3),\n",
    "                       dict(ltype='maxpool2d', kernel=2, stride=2, activation=nn.ReLU(True)),\n",
    "                       dict(ltype='linear', out_features=48, activation=nn.ReLU(True)),\n",
    "                       dict(ltype='linear', out_features=3*2)\n",
    "                      ],\n",
    "            features=[dict(ltype='conv2d', out_channels=10, kernel=3, activation=nn.ReLU(True)),\n",
    "                      dict(ltype='conv2d', out_channels=10, kernel=3),\n",
    "                      dict(ltype='maxpool2d', kernel=2, stride=2, activation=nn.ReLU(True)),\n",
    "                      dict(ltype='conv2d', out_channels=10, kernel=3, activation=nn.ReLU(True)),\n",
    "                      dict(ltype='conv2d', out_channels=10, kernel=3),\n",
    "                      dict(ltype='maxpool2d', kernel=2, stride=2, activation=nn.ReLU(True)),\n",
    "                      dict(ltype='dropout2d'),\n",
    "                      dict(ltype='linear', out_features=50),\n",
    "                      dict(ltype='linear', out_features=7)\n",
    "                     ])\n",
    "net = AttentionalNet(atn_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f139d-22f2-48c0-b144-3607a0b917af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the architecture in plain taext format\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01977915-fbb9-4f6f-b4fb-f54dbe1eff75",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e359d-b179-4b22-9ff4-a6a121cb7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)  # for adaptive learning rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673d54e-9e0f-468f-8441-18610c9e4bfa",
   "metadata": {},
   "source": [
    "---\n",
    "## Training the neural network\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346eec51-aa23-415f-aea4-09c10fa3c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model by supplying the netwrok object, loss function, optimizer, learning rate adjuster (scheduler), \n",
    "# trainloader and number of times to go over the dataset.\n",
    "# The scheduler is optional and can be None. It can also be a list of several schedulers\n",
    "\n",
    "num_epochs = 30\n",
    "train(net, criterion, optimizer, scheduler, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6daf17-a1ae-4c96-83f6-32b0a27acc60",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fecbb-f7eb-414b-829b-385f5534a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of folds to split the datasets into\n",
    "# Define a grid of parameter values to check (if more then one param is tested - supply list of tuples as a grid)\n",
    "# Define the objective function by using cross_validate() method that will accept iterated values of object(s) using \n",
    "# the parameter(s)\n",
    "\n",
    "Kfolds = 8\n",
    "momentum_grid = [0.5, 0.7, 0.9]\n",
    "optim_grid = partial(optim.SGD, net.parameters(), lr=0.001) \n",
    "objective = lambda m: cross_validate(Kfolds, dataset, net, criterion, optim_grid(momentum=m), scheduler, emotion_dict, batch_size) \n",
    "bestval = grid_search(objective, momentum_grid, 'momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9033f-fc94-4b23-9c31-8bc92c2e3426",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6967ef-dddf-45fd-ba6b-3402745cf8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained network on the testing dataset\n",
    "# Supply the network object, loss function, testloader and dictionary of class labels\n",
    "# The function will return a DataFrame with the network average loss and accuracy per class. \n",
    "# Pass this df to save_model() function in the next cell if you think it is a good model\n",
    "\n",
    "result = check_accuracy_(net, criterion, testloader, emotion_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90dcf80-e109-4b9f-8665-9248d99fb898",
   "metadata": {},
   "source": [
    "---\n",
    "## Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6fdb1-132a-4aea-b2e0-fb844e9e794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current model by supplying the net object, the parameters needed to initialize it from scratch (can be None),\n",
    "# the loss function, the optimizer, the number of epochs used in training, the testing results DataFrame \n",
    "# and a random batch (needed for saving in ONNX format for further visualisation)\n",
    "\n",
    "model_name = save_model(net, layers, criterion, optimizer, scheduler, num_epochs, result, next(iter(trainloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c1702-7359-4f10-b327-e78c4c7cb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the name of the spec file of a model (without the extension) to load\n",
    "# previously saved model as well as config with parameters used\n",
    "\n",
    "mod_name = None # Assign the name of previously saved model\n",
    "net, cfg = load_model(mod_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edf3da-9aa3-470b-9fb1-ca7acd9b0356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
